{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NLP-lab :  Plongements de mots (word embeddings)\n",
    "\n",
    "                                            Christopher Kermorvant\n",
    "\n",
    "                            “The meaning of a word can be inferred by the company it keeps”\n",
    "\n",
    "Dans cette série d'exercices, nous allons explorer  trois  plongements (embeddings) de mots :\n",
    "\n",
    "*  [Collobert & Weston](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) https://ronan.collobert.com/senna/\n",
    "* [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "* [BERT](https://huggingface.co/bert-base-uncased) \n",
    "\n",
    "   \n",
    "Pour les deux premiers, nous examinerons les mots les plus proches et visualiserons leurs positions dans l'espaces après réduction de dimension. Puis nous procéderons à des [évaluations](https://arxiv.org/pdf/1801.09536.pdf) qualitatives et intrinsèques des embeddings.\n",
    "\n",
    "Enfin nous étudierons les raisonnements par analogies que l'on peut conduire par l'arithmétique sur les embeddings (et leurs biais).\n",
    "\n",
    "Pour BERT, nous étudierons la représentation d'un mot polysémique en fonction de son contexte.\n",
    "\n",
    "Dans le code déjà fourni, ajouter votre code à l'endroit indiqué par `YOUR CODE HERE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "\n",
    "# disable warnings for libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# configure logger\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: virtualenv: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nlp-env/bin/activate: No such file or directory\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.10/site-packages (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (6.29.5)\n",
      "Collecting numpy==2.2.3 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 2))\n",
      "  Using cached numpy-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting scipy==1.15.1 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 3))\n",
      "  Using cached scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn==1.6.1 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4))\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib==3.10.0 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn==0.13.2 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 6))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting gensim==4.3.3 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 7))\n",
      "  Using cached gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (8.35.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (5.14.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.6.1->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5)) (2.9.0.post0)\n",
      "Collecting pandas>=1.2 (from seaborn==0.13.2->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 6))\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "INFO: pip is looking at multiple versions of gensim to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 3), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 6), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 7) and numpy==2.2.3 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested numpy==2.2.3\n",
      "    scipy 1.15.1 depends on numpy<2.5 and >=1.23.5\n",
      "    scikit-learn 1.6.1 depends on numpy>=1.19.5\n",
      "    matplotlib 3.10.0 depends on numpy>=1.23\n",
      "    seaborn 0.13.2 depends on numpy!=1.24.0 and >=1.20\n",
      "    gensim 4.3.3 depends on numpy<2.0 and >=1.18.5\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m[Errno 13] Permission denied: '/usr/local/share/jupyter'\n"
     ]
    }
   ],
   "source": [
    "# Créer un environnement virtuel avec Python 3\n",
    "!virtualenv -p python3 nlp-env\n",
    "\n",
    "# Activer l'environnement virtuel\n",
    "!source nlp-env/bin/activate\n",
    "\n",
    "# Installer les packages requis depuis le fichier requirements.txt\n",
    "!pip install -r ~/nlp-lab-text-embedding/requirements.txt\n",
    "\n",
    "# Enregistrer l'environnement virtuel avec Jupyter\n",
    "!python -m ipykernel install --name=nlp-env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Les fichiers d'embeddings pré-entraînés\n",
    "\n",
    "Téléchargez dans `data` les fichiers contenant les embeddings :\n",
    "* Collobert (taille 50) : [collobert_embeddings.txt.zip](https://storage.teklia.com/shared/deepnlp-labs/collobert_embeddings.txt.zip) qui contient les vecteurs d'embeddings  et [collobert_words.lst](https://storage.teklia.com/shared/deepnlp-labs/collobert_words.lst) qui contient les mots associés;\n",
    "* Glove (taille 50):  [glove.6B.50d.txt.zip](https://storage.teklia.com/shared/deepnlp-labs/glove.6B.50d.txt.zip) qui contient à la fois les vecteurs et les mots.\n",
    "\n",
    "Il faut décompresser les fichiers pour pouvoir les charger.\n",
    "\n",
    "N'hésitez pas à ouvrir les fichiers pour voir ce qu'ils contiennent (c'est parfois surprennant).\n",
    "\n",
    "#### Question : \n",
    ">* Donner la taille des fichiers d'embeddings avant unzip\n",
    ">* En explorant le contenu des fichiers d'embedding, donner le nombre de mots pour lesquels ces fichiers fournissent des embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant unzip :\n",
    "- collobert : 24275 ko\n",
    "- glove : 67618 ko\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130000\n"
     ]
    }
   ],
   "source": [
    "def nombre_lignes(fichier):\n",
    "    with open(fichier, \"r\", encoding=\"utf-8\") as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "nombre_de_lignes = nombre_lignes(\"data/collobert_embeddings.txt\")\n",
    "print(nombre_de_lignes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc collobert contient l'embedding pour 130 000 mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des embeddings\n",
    "\n",
    "### Liste des mots les plus proches\n",
    "\n",
    "L'objectif de cet exercice est de lister les mots les plus proches d'un mot donné pour l'embeddings Collobert. Dans un premier temps, nous allons charger les vecteurs de l'embedding Collobert dans un array numpy et les mots associés dans une liste python. Ensuite, nous utiliserons la structure de données [KDTree de scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html) pour faire une recherche rapide des vecteurs les plus proches d'une série de mots.\n",
    "\n",
    "### Chargement des embeddings\n",
    "\n",
    "#### Question : \n",
    ">* charger les vecteurs d'embeddings à partir du fichier `data/collobert_embeddings.txt` en utilisant la fonction numpy [genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html)\n",
    ">* charger dans une liste python les mots associés aux vecteurs à partir du fichier `data/collobert_words.lst` (avec `open()` et `readlines()`)\n",
    ">* vérifiez que les tailles sont correctes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (2.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130000\n",
      "130000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# charger les vecteurs d'embeddings\n",
    "embeddings = np.genfromtxt(\"data/collobert_embeddings.txt\", delimiter=' ')\n",
    "\n",
    "# charger les mots associés\n",
    "with open(\"data/collobert_words.lst\", \"r\", encoding=\"utf-8\") as f:\n",
    "    collobert_words = f.readlines()\n",
    "\n",
    "# enlever les espaces en fin de ligne\n",
    "collobert_words = [word.strip() for word in collobert_words]\n",
    "\n",
    "print(len(collobert_words))\n",
    "print(embeddings.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les arbres KD (KD tree) sont une structure de données très efficace pour stocker de grands ensemble de points dans une espace multi-dimensionnel et faire des recherches très efficaces de plus proches voisins. \n",
    "\n",
    "#### Question \n",
    "> * Initialisez la structure de [KDTree](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html) avec les vecteurs d'embeddings de Collobert\n",
    "> * En utilisant la fonction [tree.query](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.query.html#scipy.spatial.KDTree.query), afficher les 5 mots les plus proches des mots suivants : 'mother', 'computer', 'dentist', 'war', 'president', 'secretary', 'nurse' \n",
    "     * *Indice : vous pouvez utiliser la fonction `collobert_words.index(w)` pour obtenir l'indice d'un mot dans la liste des mots*\n",
    "> * Créer une liste `words_plus_neighbors` contenant les mots et tous leurs voisins (pour la question suivante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in ./.venv/lib/python3.10/site-packages (from scipy) (2.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 5 mots les plus proches de 'mother':\n",
      "daughter\n",
      "wife\n",
      "father\n",
      "husband\n",
      "son\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mother', 'daughter', 'wife', 'father', 'husband', 'son']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tree = KDTree(embeddings)\n",
    "\n",
    "def mot_proche(mot, k=5):\n",
    "    if mot not in collobert_words:\n",
    "        print(\"mot pas dedans\")\n",
    "        return [], []  # Retourne des listes vides si le mot n'est pas trouvé\n",
    "    \n",
    "    index = collobert_words.index(mot)\n",
    "    vecteur = embeddings[index]\n",
    "\n",
    "    # trouver les k plus proches voisins\n",
    "    distances, indices = tree.query(vecteur, k=k+1)  # k+1 pour inclure le mot lui-même\n",
    "    \n",
    "    # initialiser la liste des mots et voisins\n",
    "    words_plus_neighbors = [mot]\n",
    "    \n",
    "    # ajouter les voisins à la liste\n",
    "    for i in range(1, k+1):  # commencer à 1 pour ignorer le mot lui-même\n",
    "        words_plus_neighbors.append(collobert_words[indices[i]])\n",
    "    \n",
    "    # afficher les voisins\n",
    "    print(f\"Les {k} mots les plus proches de '{mot}':\")\n",
    "    for word in words_plus_neighbors[1:]:  # on exclut le mot lui-même\n",
    "        print(word)\n",
    "    \n",
    "    return words_plus_neighbors, indices\n",
    "\n",
    "words_plus_neighbors, indices = mot_proche('mother', k=5)\n",
    "words_plus_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation avec T-SNE\n",
    "\n",
    "Les embeddings sont des vecteurs de plusieurs centaines de dimensions. Il n'est donc pas possible de les visualiser dans leur espace d'origine. Il est par contre possible d'appliquer des algorithmes de réduction de dimension pour les visualiser en 2 ou 3 dimension. Un des algorithmes de réduction de dimension permettant une visualisation en 2D est [tSNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding). \n",
    "\n",
    "#### Question\n",
    "> * créer un object `word_vectors` de type `np.array` à partir d'une liste contenant tous les embeddings des mots de la liste `words_plus_neighbors`\n",
    "> * créer un objet tSNE à partir de la librairie `from sklearn.manifold import TSNE` avec les paramètres `random_state=0`, `n_iter=2000` et `perplexity=15.0` pour une visualisation en 2 dimensions\n",
    "> * Calculer *T* la transformation tSNE des vecteur `word_vectors` en appliquant la function `.fit_transform(word_vectors)` à l'objet tSNE. Cette fonction estime les paramètres de la transformation tSNE et retourne la représentation en dimension réduite des vecteurs utilisés pour l'estimation.\n",
    "> * Utiliser la fonction `scatterplot` de [seaborn](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) pour représenter les points en 2 dimensions  et ajouter les labels des mots avec la function `plt.annotate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.10/site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.10/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 5 mots les plus proches de 'mother':\n",
      "daughter\n",
      "wife\n",
      "father\n",
      "husband\n",
      "son\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt\n",
    "# display matplotlib graphics in notebook\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "# récupérer les voisins et leurs embeddings\n",
    "words_plus_neighbors, indices = mot_proche(\"mother\")\n",
    "word_vectors = embeddings[indices]\n",
    "\n",
    "# créer l'objet tSNE\n",
    "tsne = TSNE(random_state=0, n_iter=2000, perplexity=2.0)\n",
    "\n",
    "# appliquer la transformation tSNE\n",
    "T = tsne.fit_transform(word_vectors)\n",
    "\n",
    "# initialiser le graphique\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('#f9f9f9')\n",
    "\n",
    "# configurer les paramètres d'affichage\n",
    "sns.set(rc={'figure.figsize': (14, 8)})\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "# tracer les points dans le graphique\n",
    "sns.scatterplot(x=T[:, 0], y=T[:, 1])\n",
    "\n",
    "# annoter chaque point avec son mot\n",
    "for label, x, y in zip(words_plus_neighbors, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x + 1, y + 1), xytext=(0, 0), textcoords='offset points')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation des embeddings \n",
    "\n",
    "### Évaluation intrinsèque\n",
    "\n",
    "[A Survey of Word Embeddings Evaluation Methods](https://arxiv.org/pdf/1801.09536.pdf), Bakarov, 2018.\n",
    "\n",
    "\n",
    ">les distances entre les mots dans un espace vectoriel pourraient être évaluées à l'aide des jugements heuristiques humains sur les distances sémantiques réelles entre ces mots (par exemple, la distance entre tasse et gobelet définies dans un intervalle continu 0, 1 serait 0.8 puisque ces mots sont synonymes, mais pas vraiment la même chose).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des datasets pré-établis et annotés manuellement\n",
    "\n",
    "Nous allons utiliser 4 jeux de données  pour évaluer la qualité des embeddings : [MEN](http://clic.cimec.unitn.it/~elia.bruni/MEN.html), [WS353R](http://www.aclweb.org/anthology/N09-1003.pdf), [SimLex999](http://leviants.com/ira.leviant/MultilingualVSMdata.html) et [MTurk](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.205.8607&rep=rep1&type=pdf). \n",
    "\n",
    "\n",
    "Ces jeux de données contiennent des paires de mots dont la proximité sémantique a été évaluée manuellement par des humains. Pour chaque dataset, dataset.X contient une liste de paires de mots et dataset.y contient le score de proximité pour chaque paire.\n",
    "\n",
    "* MEN, 3 000 paires évaluées par relation sémantique avec une échelle discrète de 0 à 50\n",
    "* SimLex-999, 999 paires évaluées avec un fort respect pour la similarité sémantique avec une échelle de 0 à 10\n",
    "* MTurk-287, 287 paires évaluées par relation sémantique avec une échelle de 0 à 5\n",
    "* WordSim-353, 353 paires évaluées par similarité sémantique (cependant, certains chercheurs trouvent les instructions pour les évaluateurs ambiguës en ce qui concerne la similarité et l'association) sur une échelle de 0 à 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: similarity in ./.venv/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: editdistance in ./.venv/lib/python3.10/site-packages (from similarity) (0.8.1)\n",
      "Requirement already satisfied: jellyfish in ./.venv/lib/python3.10/site-packages (from similarity) (1.2.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from similarity) (2.2.4)\n",
      "Requirement already satisfied: interaction in ./.venv/lib/python3.10/site-packages (from similarity) (1.3)\n",
      "Requirement already satisfied: polyglot in ./.venv/lib/python3.10/site-packages (16.7.4)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install similarity\n",
    "!pip install polyglot\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MEN dataset: similarity and relatedness\n",
      "Downloading WS353 dataset: attributional and relatedness similarity\n",
      "Downloading SimLex999 dataset: attributional similarity\n",
      "Downloading MTurk dataset: attributional similarity\n",
      "\n",
      " MEN : 3000 items\n",
      "     sun, sunlight : [10.]\n",
      "     automobile, car : [10.]\n",
      "     river, water : [9.8]\n",
      "     stair, staircase : [9.8]\n",
      "\n",
      " WS353R : 252 items\n",
      "     computer, keyboard : 7.62\n",
      "     Jerusalem, Israel : 8.46\n",
      "     planet, galaxy : 8.11\n",
      "     canyon, landscape : 7.53\n",
      "\n",
      " SimLex999 : 999 items\n",
      "     old, new : 1.58\n",
      "     smart, intelligent : 9.2\n",
      "     hard, difficult : 8.77\n",
      "     happy, cheerful : 9.55\n",
      "\n",
      " MTurk : 287 items\n",
      "     episcopal, russia : 5.5\n",
      "     water, shortage : 5.428571428\n",
      "     horse, wedding : 4.533333334\n",
      "     plays, losses : 6.4\n"
     ]
    }
   ],
   "source": [
    "# custom functions\n",
    "import similarity\n",
    "\n",
    "similarity_tasks = {\n",
    "    \"MEN\": similarity.fetch_MEN(),\n",
    "    \"WS353R\": similarity.fetch_WS353(which=\"relatedness\"),\n",
    "    \"SimLex999\": similarity.fetch_SimLex999(),\n",
    "    \"MTurk\": similarity.fetch_MTurk(),\n",
    "}\n",
    "\n",
    "for name, dataset in similarity_tasks.items():\n",
    "    print('\\n', name, ':',len(dataset.X),'items')\n",
    "    for data, score in zip(dataset.X[:4], dataset.y[:4]):\n",
    "        print(' '*4, ', '.join(data), ':', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats évaluation intrinsèque\n",
    "\n",
    "Notre objectif est de comparer les similarités entre les paires de mots des datasets calculées à partir des embeddings et celles données par les annotateurs humains. Si un embedding prédit les similarités de la même manière que les humains, on estime qu'il est bon. On peut donc calculer la corrélation entre la proximité donné par l'embedding et celle donnée par les humains pour chaque paire de mots du dataset.\n",
    "\n",
    "Pour cet excercice, nous allons utiliser  le classe [Embeddings](https://polyglot.readthedocs.io/en/latest/polyglot.mapping.html#module-polyglot.mapping.embeddings) de polyglot. Pour charger un embeddind avec cette classe : \n",
    "\n",
    "`glove_embeddings =  Embedding.from_glove('data/glove.6B.50d.txt')`\n",
    "\n",
    "Pour pouvoir charger les embeddings de Collobert de la même manière, il faut mettre les mots et les vecteurs dans un seul fichier, par exemple avec la commande linux `paste`:\n",
    "\n",
    "`paste -d ' ' collobert_words.lst collobert_embeddings.txt > collobert.txt`\n",
    "\n",
    "\n",
    "\n",
    "#### Question\n",
    "\n",
    "> * pour chaque embedding Collober et Glove, et chaque dataset (MEN, WS353R, SimLex999 et MTurk), calculer la similarité entre les proximités données par l'embedding et celles données par les humains. On utilisera la fonction `similarity.evaluate_similarity(word_embeddings, dataset.X, dataset.y)` qui renvoit le [coefficient de correlation de Spearman](https://fr.wikipedia.org/wiki/Corr%C3%A9lation_de_Spearman).\n",
    "> * stocker les scores  pour chaque embedding et chaque dataset dans une liste `similarity_results = []` sous forme d'un dictonnaire : `similarity_results.append({'Embeddings': embeddings_name, 'Dataset': name, 'Score': score})`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/onyxia/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/numpy/_core/_methods.py:137: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "arrays to stack must be passed as a \"sequence\" type such as list or tuple.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embeddings_name, embeddings \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollobert\u001b[39m\u001b[38;5;124m'\u001b[39m, collobert_embed), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglove\u001b[39m\u001b[38;5;124m'\u001b[39m, glove_embed)]:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Loop on datasets\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, dataset \u001b[38;5;129;01min\u001b[39;00m similarity_tasks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Compute similarity\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         score \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Store the result in the list as a dictionary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         similarity_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: embeddings_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m: name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m'\u001b[39m: score})\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/similarity.py:401\u001b[0m, in \u001b[0;36mevaluate_similarity\u001b[0;34m(w, X, y)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m#if missing_words > 0:\u001b[39;00m\n\u001b[1;32m    397\u001b[0m  \u001b[38;5;66;03m#   logger.warning(\"Missing {} words. Will replace them with mean vector\".format(missing_words))\u001b[39;00m\n\u001b[1;32m    400\u001b[0m mean_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(w\u001b[38;5;241m.\u001b[39mvectors, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 401\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_vector\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(w\u001b[38;5;241m.\u001b[39mget(word, mean_vector) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m X[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    403\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([v1\u001b[38;5;241m.\u001b[39mdot(v2\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m/\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(v1) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(v2)) \u001b[38;5;28;01mfor\u001b[39;00m v1, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(A, B)])\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/numpy/_core/shape_base.py:217\u001b[0m, in \u001b[0;36m_vhstack_dispatcher\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_vhstack_dispatcher\u001b[39m(tup, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_arrays_for_stack_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/numpy/_core/shape_base.py:210\u001b[0m, in \u001b[0;36m_arrays_for_stack_dispatcher\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_arrays_for_stack_dispatcher\u001b[39m(arrays):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arrays, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrays to stack must be passed as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuch as list or tuple.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(arrays)\n",
      "\u001b[0;31mTypeError\u001b[0m: arrays to stack must be passed as a \"sequence\" type such as list or tuple."
     ]
    }
   ],
   "source": [
    "from polyglot.mapping import Embedding\n",
    "import numpy as np\n",
    "\n",
    "results_similarity = []\n",
    "\n",
    "# Charger les embeddings en utilisant la fonction Embedding.from_glove de Polyglot\n",
    "glove_embed = Embedding.from_glove('data/glove.6B.50d.txt')\n",
    "collobert_embed = Embedding.from_glove('data/collobert.txt')\n",
    "\n",
    "for embeddings_name, embeddings in [('collobert', collobert_embed), ('glove', glove_embed)]:\n",
    "    # Loop on datasets\n",
    "    for name, dataset in similarity_tasks.items():\n",
    "        # Compute similarity\n",
    "        score = similarity.evaluate_similarity(embeddings, dataset.X, dataset.y)\n",
    "        \n",
    "        # Store the result in the list as a dictionary\n",
    "        similarity_results.append({'Embeddings': embeddings_name, 'Dataset': name, 'Score': score})\n",
    "\n",
    "# Print the results\n",
    "for result in similarity_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des résultats de similarité\n",
    "\n",
    "Le code suivant permet de visualiser les coefficients de corrélation pour chaque dataset sur les différents jeux de test.\n",
    "\n",
    "#### Question\n",
    "> * Quel est selon ces métriques le meilleur embedding ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `Dataset` for `x`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mset(font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#e74c3c\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#75d9fc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#b4e0ef\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#34495e\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#e74c3c\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#2ecc71\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mScore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEmbeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolor_palette\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m ax\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, bbox_to_anchor\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m), ncol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, fancybox\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shadow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m ax\u001b[38;5;241m.\u001b[39mset(xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/seaborn/categorical.py:2341\u001b[0m, in \u001b[0;36mbarplot\u001b[0;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, seed, units, weights, orient, color, palette, saturation, fill, hue_norm, width, dodge, gap, log_scale, native_scale, formatter, legend, capsize, err_kws, ci, errcolor, errwidth, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlen\u001b[39m:\n\u001b[1;32m   2339\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2341\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43m_CategoricalAggPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2351\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/seaborn/categorical.py:67\u001b[0m, in \u001b[0;36m_CategoricalPlotter.__init__\u001b[0;34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     58\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m ):\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/seaborn/_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/seaborn/_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/seaborn/_core/data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     data: DataSource,\n\u001b[1;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[1;32m     55\u001b[0m ):\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[0;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n",
      "File \u001b[0;32m~/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/seaborn/_core/data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn entry with this name does not appear in `data`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `Dataset` for `x`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame.from_dict(results_similarity, orient='columns')\n",
    "df\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('#f9f9f9')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8, 6)})\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "colors = [\"#e74c3c\", \"#75d9fc\", \"#b4e0ef\", \"#34495e\", \"#e74c3c\", \"#2ecc71\"]\n",
    "ax = sns.barplot(x=\"Dataset\", y=\"Score\", hue=\"Embeddings\", data=df, errwidth=0, palette=sns.color_palette(colors))\n",
    "\n",
    "ax.legend(loc=9, bbox_to_anchor=(0.5, -0.1), ncol=3, fancybox=True, shadow=False)\n",
    "ax.set(xlabel=\"\", ylabel=\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation d'analogies\n",
    "\n",
    "Notre objectif est maintenant d'explorer les relations sémantiques induites par l'arithmétique sur les embeddings. Nous allons donc explorer les analogies induites par les embeddings sous forme de raisonnement du type : \"l'homme est au roi ce que la femme est à ?\", la réponse étant \"la reine\". On peut calculer la réponse avec les représentations fournies par l'embedding par :  \n",
    "\n",
    "`v = vecteur(roi)-vecteur(homme)+vecteur(femme)`. \n",
    "\n",
    "La réponse étant alors le mot dont la représentation est la plus proche du vecteur `v`. Pour trouver le mot dont le vecteur est le plus proche de `v`, il faut définir une distance dans l'espace des embeddings. Nous utiliserons la [similarité cosinus](https://fr.wikipedia.org/wiki/Similarit%C3%A9_cosinus)\n",
    "\n",
    "#### Question\n",
    ">* Implémenter la similarity cosinus à l'aide des fonctions [np.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html#numpy.dot) et [np.linalg.norm](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm)\n",
    ">* Appliquer le calcul d'analogies sur les triplets proposés ou ceux de votre choix. Observez-vous [ce phénomène](https://arxiv.org/pdf/1607.06520.pdf) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('woman' in collobert_embeddings.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman + king - man = ? queen\n",
      "programmer + woman - man = ? therapist\n",
      "doctor + mother - father = ? nurse\n",
      "facebook + mother - father = ? myspace\n"
     ]
    }
   ],
   "source": [
    "def my_cosine_similarity(a,b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "glove_embeddings = Embedding.from_glove('data/glove.6B.50d.txt')\n",
    "collobert_embeddings = Embedding.from_glove('data/collobert.txt')\n",
    "\n",
    "def sorted_by_similarity(word_embeddings, base_vector):\n",
    "    \"\"\"Returns words sorted by cosine distance to a given vector, most similar first\"\"\"\n",
    "    words_with_distance = [(my_cosine_similarity(base_vector, word_embeddings[w]), w) \n",
    "                           for w in word_embeddings.vocabulary]\n",
    "\n",
    "    return sorted(words_with_distance, key=lambda t: t[0], reverse=True)\n",
    "\n",
    "def is_redundant(word):\n",
    "    return (\n",
    "        word_1.lower() in word.lower() or\n",
    "        word_2.lower() in word.lower() or\n",
    "        word_3.lower() in word.lower())\n",
    "\n",
    "\n",
    "pairs = [(['man', 'woman'], 'king'), \n",
    "         (['man', 'programmer'], 'woman'), \n",
    "         (['father', 'doctor'], 'mother'),\n",
    "         (['father', 'facebook'], 'mother')\n",
    "        ]\n",
    "\n",
    "words_and_responses = []\n",
    "\n",
    "# Note : you may need to update the following line with your Polyglot Embeddings\n",
    "for embeddings_name, embeddings in [('glove', glove_embeddings)]:\n",
    "    for pair in pairs:\n",
    "        word_1, word_2, word_3 = pair[0][0], pair[0][1], pair[1]\n",
    "        \n",
    "        closest = sorted_by_similarity(embeddings, \n",
    "                                       embeddings[word_2] - embeddings[word_1] + \n",
    "                                       embeddings[word_3])[:10]\n",
    "\n",
    "        closest = [(dist, w) for (dist, w) in closest if not is_redundant(w)] #\n",
    "        \n",
    "        print(\"{} + {} - {} = ? {}\".format(word_2, word_3, word_1, closest[0][1]))\n",
    "        words_and_responses += [word_1, word_2, word_3,closest[0][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des analogies\n",
    "\n",
    "Les relations d'analogies peuvent se visualiser dans l'espace des embeddings après réduction de dimension, par exemple avec tSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/nlp-lab-text-embedding/.venv/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# Note : you may need to update the following line with your Polyglot Embeddings\n",
    "for embeddings_name, embeddings in [('glove', glove_embeddings)]:\n",
    "    \n",
    "    word_vectors = np.array([embeddings[word] for word in words_and_responses[:4]])\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=0, n_iter=1000, perplexity=3.0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    T = tsne.fit_transform(word_vectors)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('#f9f9f9')\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(6, 6)})\n",
    "    sns.set(font_scale=1.3)\n",
    "\n",
    "    sns.scatterplot(x=T[:, 0], y=T[:, 1])\n",
    "    \n",
    "    for label, x, y in zip(words_and_responses, T[:, 0], T[:, 1]):\n",
    "        plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation des embeddings de BERT\n",
    "\n",
    "BERT a été un des premiers modèles de langue Transformer, entraînés sur de gros corpus, disponible librement. De nombreux modèles sont disponibles sur HuggingFace.\n",
    "\n",
    "Comme BERT est un modèle contextuel, il est nécessaire de lui faire prédire des phrases entières pour étudier les embeddings de mots qu'il produit. Dans cette section, nous allons comparer les embeddings obtenus pour des mots polysémiques en fonction de la phrase dans laquelle ils sont utilisés.\n",
    "\n",
    "En anglais, *plant* possède deux sens : celui d'usine et celui d'un végétal. Avec un embedding non contextuel, de type Glove ou Colobert, ces deux sens du mot plus sont associés à un identique embedding. Avec BERT, nous allons voir que le même mot peut avoir plusieurs embeddings en fonction du contexte.\n",
    "\n",
    "First, load the BERT model and tokenizer from HuggingFace : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.10/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load pre-trained model \n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # to access the hidden states\n",
    "                                  )\n",
    "# set the model to \"evaluation\" mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Les modèles de langues sont entrainés avec un découpe spécifique des phrases en token. Ces tokens peuvent être des mots ou des parties de mots. Il est nécessaire d'utiliser le tokenizer correspondant à chaque model.\n",
    "\n",
    "tokenizer.vocab.keys() donne la liste de tous les tokens connus du modèle de langue. \n",
    "\n",
    "#### Question\n",
    ">* combien de token différents sont connu du tokenizer de BERT ?\n",
    ">* affichez une centaine de token aléatoirement. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le tokenizer BERT connaît 30522 tokens différents.\n",
      "\n",
      "100 tokens aléatoires du tokenizer BERT :\n",
      "['stanley', 'evacuated', 'committed', '江', '##sms', 'programs', 'carson', 'grasslands', 'subsistence', '1666', 'specialist', '1799', 'oils', 'criteria', 'gillespie', 'conqueror', 'maximize', 'professionals', 'drilling', 'hms', 'clint', '##aina', '##ther', '##gation', 'gathers', 'hawks', 'drowned', 'penned', 'aquatic', 'perceptions', 'থ', 'annoyed', '##♯', 'proving', '[unused792]', 'jules', 'bingo', 'mps', 'comprehensive', 'convened', '##cl', 'arjun', 'lgbt', 'preached', '##♦', 'munoz', 'ivy', 'jumped', 'graf', '##enstein', 'anglican', 'comforting', '##เ', 'intersect', 'ˡ', 'decimal', 'functioned', 'early', '##oman', 'normal', '##cliffe', 'stampede', 'holmes', '##poo', 'macmillan', 'curb', '##eft', 'exploited', '##kur', '##tral', 'slate', '##ounded', 'begins', '##tered', '8', 'airfields', '##rate', 'inning', 'friedrich', '[unused100]', 'stressed', 'daily', '##stic', '1634', 'advertising', 'turks', '[unused575]', 'islamabad', '[unused991]', 'ash', 'jillian', 'fest', 'clover', 'xu', 'volkswagen', 'environmental', 'exponential', '##⁶', 'images', 'futsal']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Charger le tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "num_tokens = len(tokenizer.vocab)\n",
    "print(f\"Le tokenizer BERT connaît {num_tokens} tokens différents.\")\n",
    "\n",
    "# Sélectionner aléatoirement 100 tokens\n",
    "sample_tokens = random.sample(list(tokenizer.vocab.keys()), 100)\n",
    "\n",
    "# Afficher les 100 tokens choisis aléatoirement\n",
    "print(\"\\n100 tokens aléatoires du tokenizer BERT :\")\n",
    "print(sample_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tokenizer découpe les phrases et transforme les éléments (mots ou sous-mots) en indice. \n",
    "\n",
    "BERT peut traiter plusieurs phrases mais il faut lui indiquer le découpage en phrases (segment) avec un indice : 0 pour la première phrases, 1 pour la deuxième. \n",
    "\n",
    "Deux tokens spécifiques doivent être aussi ajoutés : \n",
    "* [CLS], un token spécifique utilisé pour la classification de phrase\n",
    "* [SEP], le token de fin de phrase.\n",
    "\n",
    "#### Question\n",
    ">* Appliquer la fonction bert_tokenize sur les 3 phases et conservez les 3 vecteurs (index, token, segment)\n",
    ">* Affichez ces informations pour chacune des phrases et vérifier que le mot *plant* a bien le même indice de token dans les deux phrases où il apparait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 'plant' dans Phrase 1: 3269\n",
      "Token 'plant' dans Phrase 3: 3269\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "snt1 = \"The plant has reached its maximal level of production.\"\n",
    "snt2 = \"The cars are assembled inside the factory.\"\n",
    "snt3 = \"A plant needs sunlight and water to grow well.\"\n",
    "\n",
    "\n",
    "def bert_tokenize(snt):\n",
    "    \"\"\" Apply the BERT tokenizer to a list of words representing a sentence\n",
    "        and return 3 lists: \n",
    "        - list of token indx\n",
    "        - list of token for debugging, not used by the BERT model\n",
    "        - list of sentence index\n",
    "        \"\"\"\n",
    "    # Add the special tokens.\n",
    "    tagged_snt = \"[CLS] \" + snt + \" [SEP]\" \n",
    "    # Tokenize\n",
    "    tokenized_snt = tokenizer.tokenize(tagged_snt)\n",
    "    # convert tokens to indices\n",
    "    indexed_snt = tokenizer.convert_tokens_to_ids(tokenized_snt)\n",
    "    # mark the words in sentence.\n",
    "    segments_ids = [1] * len(tokenized_snt)\n",
    "\n",
    "    return (indexed_snt, tokenized_snt, segments_ids)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "sentences = [snt1, snt2, snt3]\n",
    "tokenized_sentences = [bert_tokenize(snt) for snt in sentences]\n",
    "\n",
    "# Recherche du token 'plant' dans les phrases 1 et 3\n",
    "plant_index_snt1 = tokenized_sentences[0][1].index(\"plant\")\n",
    "plant_index_snt3 = tokenized_sentences[2][1].index(\"plant\")\n",
    "\n",
    "# Affichage des tokens associés à 'plant' dans les phrases 1 et 3\n",
    "plant_token_snt1 = tokenized_sentences[0][0][plant_index_snt1]\n",
    "plant_token_snt3 = tokenized_sentences[2][0][plant_index_snt3]\n",
    "\n",
    "print(f\"Token 'plant' dans Phrase 1: {plant_token_snt1}\")\n",
    "print(f\"Token 'plant' dans Phrase 3: {plant_token_snt3}\")\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inférence\n",
    "\n",
    "Pour calculer les embeddings, il est nécessaire de faire une prédiction avec le modèle BERT sur une phrase complète. La fonction *predict_hidden* convertit les listes d'indices de token et de segment en tenseur pytorch et applique le modèle. \n",
    "\n",
    "Le modème utilisé est un modèle à 12 couches. Nous allons utiliser la dernière couche caché du modèle comme embedding pour représenter les mots. D'autres solutions serait possible, comme une concaténation ou une moyene de plusieurs couches.\n",
    "\n",
    "\n",
    "#### Question\n",
    ">* Appliquer le modèle à chacune des 3 phrases et stocker les embeddings obtenus (tenseurs)\n",
    ">* Afficher la dimension des tenseurs obtenus. Quelle est la dimension du vecteur d'embedding pour chaque mot ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_hidden(indexed_snt, segments_ids):\n",
    "    \"\"\"Apply the BERT model to the input token indices and segment indices\n",
    "        and return the last hidden layer\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_snt])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "        one_hidden_layer = hidden_states[12][0]\n",
    "        \n",
    "    return one_hidden_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de l'embedding pour la phrase 1: torch.Size([12, 768])\n",
      "Dimension du vecteur d'embedding pour chaque mot dans la phrase 1: 768\n",
      "Dimension de l'embedding pour la phrase 2: torch.Size([10, 768])\n",
      "Dimension du vecteur d'embedding pour chaque mot dans la phrase 2: 768\n",
      "Dimension de l'embedding pour la phrase 3: torch.Size([12, 768])\n",
      "Dimension du vecteur d'embedding pour chaque mot dans la phrase 3: 768\n"
     ]
    }
   ],
   "source": [
    "# Liste des phrases\n",
    "sentences = [snt1, snt2, snt3]\n",
    "\n",
    "# Tokenisation des phrases\n",
    "tokenized_sentences = [bert_tokenize(snt) for snt in sentences]\n",
    "\n",
    "# Calcul des embeddings pour chaque phrase\n",
    "embeddings = [predict_hidden(tokenized[0], tokenized[2]) for tokenized in tokenized_sentences]\n",
    "\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    word_embedding_dim = embedding.shape[1]  # Dimension de l'embedding pour chaque mot\n",
    "    print(f\"Dimension de l'embedding pour la phrase {i+1}: {embedding.shape}\")\n",
    "    print(f\"Dimension du vecteur d'embedding pour chaque mot dans la phrase {i+1}: {word_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La couche cachée renvoyée par la fonction *predict_hidden* est un tenseur contenant pour chaque token de la phrase d'entrée un vecteur contextuel le représentant. On peut utiliser ce vecteur pour représenter le sens de ce mot en fonction de son contexte. Nous allons comparer la représentation du mot polysémique *plant* en fonction de son contexte.\n",
    "\n",
    "#### Question\n",
    ">* En utilisant la [distance cosinus](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html), calculer les distances suivantes:\n",
    ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *plant* dans la phrase 3 (plant-vegetal)\n",
    ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *factory* dans la phrase 2 \n",
    ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *production* dans la phrase 2 \n",
    ">   * distance entre *plant* dans la phrase 3 (plant-vegetal) et *production* dans la phrase 2 \n",
    "> * Comment interprêter ces distances ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance cosinus entre 'plant' (usine) et 'plant' (végétal) : 0.4987\n",
      "Distance cosinus entre 'plant' (usine) et 'factory' : 0.3123\n",
      "Distance cosinus entre 'plant' (usine) et 'production' : 0.2402\n",
      "Distance cosinus entre 'plant' (végétal) et 'production' : 0.6200\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def extract_word_embedding(tokenized_sentence, sentence_embedding, target_word):\n",
    "    \"\"\"Extrait l'embedding d'un mot spécifique d'une phrase tokenisée et de son embedding\"\"\"\n",
    "    try:\n",
    "        word_index = tokenized_sentence.index(target_word)\n",
    "        return sentence_embedding[word_index].numpy()  # Retourne l'embedding du mot\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Le mot '{target_word}' n'a pas été trouvé dans la phrase.\")\n",
    "\n",
    "def calculate_cosine_distance_between_words(word1_embedding, word2_embedding):\n",
    "    \"\"\"Calcule la distance cosinus entre les embeddings de deux mots\"\"\"\n",
    "    return cosine(word1_embedding, word2_embedding)\n",
    "\n",
    "# Tokenisation des phrases\n",
    "tokens_phrase1 = bert_tokenize(snt1)\n",
    "tokens_phrase2 = bert_tokenize(snt2)\n",
    "tokens_phrase3 = bert_tokenize(snt3)\n",
    "\n",
    "# Calcul des embeddings des phrases\n",
    "embedding_phrase1 = predict_hidden(tokens_phrase1[0], tokens_phrase1[2])\n",
    "embedding_phrase2 = predict_hidden(tokens_phrase2[0], tokens_phrase2[2])\n",
    "embedding_phrase3 = predict_hidden(tokens_phrase3[0], tokens_phrase3[2])\n",
    "\n",
    "# Extraction des embeddings pour les mots spécifiques\n",
    "embedding_plant_phrase1 = extract_word_embedding(tokens_phrase1[1], embedding_phrase1, \"plant\")\n",
    "embedding_plant_phrase3 = extract_word_embedding(tokens_phrase3[1], embedding_phrase3, \"plant\")\n",
    "embedding_factory_phrase2 = extract_word_embedding(tokens_phrase2[1], embedding_phrase2, \"factory\")\n",
    "embedding_production_phrase1 = extract_word_embedding(tokens_phrase1[1], embedding_phrase1, \"production\")\n",
    "\n",
    "# Calcul des distances cosinus\n",
    "dist_plant_vs_plant = calculate_cosine_distance_between_words(embedding_plant_phrase1, embedding_plant_phrase3)\n",
    "dist_plant_vs_factory = calculate_cosine_distance_between_words(embedding_plant_phrase1, embedding_factory_phrase2)\n",
    "dist_plant_vs_production = calculate_cosine_distance_between_words(embedding_plant_phrase1, embedding_production_phrase1)\n",
    "dist_plant_vs_production_phrase3 = calculate_cosine_distance_between_words(embedding_plant_phrase3, embedding_production_phrase1)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Distance cosinus entre 'plant' (usine) et 'plant' (végétal) : {dist_plant_vs_plant:.4f}\")\n",
    "print(f\"Distance cosinus entre 'plant' (usine) et 'factory' : {dist_plant_vs_factory:.4f}\")\n",
    "print(f\"Distance cosinus entre 'plant' (usine) et 'production' : {dist_plant_vs_production:.4f}\")\n",
    "print(f\"Distance cosinus entre 'plant' (végétal) et 'production' : {dist_plant_vs_production_phrase3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
