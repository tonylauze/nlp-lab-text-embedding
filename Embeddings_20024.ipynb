{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NLP-lab :  Plongements de mots (word embeddings)\n",
    "\n",
    "                                            Christopher Kermorvant\n",
    "\n",
    "                            “The meaning of a word can be inferred by the company it keeps”\n",
    "\n",
    "Dans cette série d'exercices, nous allons explorer  trois  plongements (embeddings) de mots :\n",
    "\n",
    "*  [Collobert & Weston](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) https://ronan.collobert.com/senna/\n",
    "* [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "* [BERT](https://huggingface.co/bert-base-uncased) \n",
    "\n",
    "   \n",
    "Pour les deux premiers, nous examinerons les mots les plus proches et visualiserons leurs positions dans l'espaces après réduction de dimension. Puis nous procéderons à des [évaluations](https://arxiv.org/pdf/1801.09536.pdf) qualitatives et intrinsèques des embeddings.\n",
    "\n",
    "Enfin nous étudierons les raisonnements par analogies que l'on peut conduire par l'arithmétique sur les embeddings (et leurs biais).\n",
    "\n",
    "Pour BERT, nous étudierons la représentation d'un mot polysémique en fonction de son contexte.\n",
    "\n",
    "Dans le code déjà fourni, ajouter votre code à l'endroit indiqué par `YOUR CODE HERE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "\n",
    "# disable warnings for libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# configure logger\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: virtualenv: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nlp-env/bin/activate: No such file or directory\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.10/site-packages (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (6.29.5)\n",
      "Collecting numpy==2.2.3 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 2))\n",
      "  Using cached numpy-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting scipy==1.15.1 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 3))\n",
      "  Using cached scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn==1.6.1 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4))\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib==3.10.0 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn==0.13.2 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 6))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting gensim==4.3.3 (from -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 7))\n",
      "  Using cached gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (8.35.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.10/site-packages (from ipykernel==6.29.5->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 1)) (5.14.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.6.1->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib==3.10.0->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5)) (2.9.0.post0)\n",
      "Collecting pandas>=1.2 (from seaborn==0.13.2->-r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 6))\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "INFO: pip is looking at multiple versions of gensim to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 3), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 4), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 5), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 6), -r /home/onyxia/nlp-lab-text-embedding/requirements.txt (line 7) and numpy==2.2.3 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested numpy==2.2.3\n",
      "    scipy 1.15.1 depends on numpy<2.5 and >=1.23.5\n",
      "    scikit-learn 1.6.1 depends on numpy>=1.19.5\n",
      "    matplotlib 3.10.0 depends on numpy>=1.23\n",
      "    seaborn 0.13.2 depends on numpy!=1.24.0 and >=1.20\n",
      "    gensim 4.3.3 depends on numpy<2.0 and >=1.18.5\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m[Errno 13] Permission denied: '/usr/local/share/jupyter'\n"
     ]
    }
   ],
   "source": [
    "# Créer un environnement virtuel avec Python 3\n",
    "!virtualenv -p python3 nlp-env\n",
    "\n",
    "# Activer l'environnement virtuel\n",
    "!source nlp-env/bin/activate\n",
    "\n",
    "# Installer les packages requis depuis le fichier requirements.txt\n",
    "!pip install -r ~/nlp-lab-text-embedding/requirements.txt\n",
    "\n",
    "# Enregistrer l'environnement virtuel avec Jupyter\n",
    "!python -m ipykernel install --name=nlp-env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Les fichiers d'embeddings pré-entraînés\n",
    "\n",
    "Téléchargez dans `data` les fichiers contenant les embeddings :\n",
    "* Collobert (taille 50) : [collobert_embeddings.txt.zip](https://storage.teklia.com/shared/deepnlp-labs/collobert_embeddings.txt.zip) qui contient les vecteurs d'embeddings  et [collobert_words.lst](https://storage.teklia.com/shared/deepnlp-labs/collobert_words.lst) qui contient les mots associés;\n",
    "* Glove (taille 50):  [glove.6B.50d.txt.zip](https://storage.teklia.com/shared/deepnlp-labs/glove.6B.50d.txt.zip) qui contient à la fois les vecteurs et les mots.\n",
    "\n",
    "Il faut décompresser les fichiers pour pouvoir les charger.\n",
    "\n",
    "N'hésitez pas à ouvrir les fichiers pour voir ce qu'ils contiennent (c'est parfois surprennant).\n",
    "\n",
    "#### Question : \n",
    ">* Donner la taille des fichiers d'embeddings avant unzip\n",
    ">* En explorant le contenu des fichiers d'embedding, donner le nombre de mots pour lesquels ces fichiers fournissent des embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant unzip :\n",
    "- collobert : 24275 ko\n",
    "- glove : 67618 ko\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130000\n"
     ]
    }
   ],
   "source": [
    "def nombre_lignes(fichier):\n",
    "    with open(fichier, \"r\", encoding=\"utf-8\") as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "nombre_de_lignes = nombre_lignes(\"data/collobert_embeddings.txt\")\n",
    "print(nombre_de_lignes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc collobert contient l'embedding pour 130 000 mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des embeddings\n",
    "\n",
    "### Liste des mots les plus proches\n",
    "\n",
    "L'objectif de cet exercice est de lister les mots les plus proches d'un mot donné pour l'embeddings Collobert. Dans un premier temps, nous allons charger les vecteurs de l'embedding Collobert dans un array numpy et les mots associés dans une liste python. Ensuite, nous utiliserons la structure de données [KDTree de scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html) pour faire une recherche rapide des vecteurs les plus proches d'une série de mots.\n",
    "\n",
    "### Chargement des embeddings\n",
    "\n",
    "#### Question : \n",
    ">* charger les vecteurs d'embeddings à partir du fichier `data/collobert_embeddings.txt` en utilisant la fonction numpy [genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html)\n",
    ">* charger dans une liste python les mots associés aux vecteurs à partir du fichier `data/collobert_words.lst` (avec `open()` et `readlines()`)\n",
    ">* vérifiez que les tailles sont correctes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (2.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130000\n",
      "130000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# charger les vecteurs d'embeddings\n",
    "embeddings = np.genfromtxt(\"data/collobert_embeddings.txt\", delimiter=' ')\n",
    "\n",
    "# charger les mots associés\n",
    "with open(\"data/collobert_words.lst\", \"r\", encoding=\"utf-8\") as f:\n",
    "    collobert_words = f.readlines()\n",
    "\n",
    "# enlever les espaces en fin de ligne\n",
    "collobert_words = [word.strip() for word in collobert_words]\n",
    "\n",
    "print(len(collobert_words))\n",
    "print(embeddings.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les arbres KD (KD tree) sont une structure de données très efficace pour stocker de grands ensemble de points dans une espace multi-dimensionnel et faire des recherches très efficaces de plus proches voisins. \n",
    "\n",
    "#### Question \n",
    "> * Initialisez la structure de [KDTree](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html) avec les vecteurs d'embeddings de Collobert\n",
    "> * En utilisant la fonction [tree.query](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.query.html#scipy.spatial.KDTree.query), afficher les 5 mots les plus proches des mots suivants : 'mother', 'computer', 'dentist', 'war', 'president', 'secretary', 'nurse' \n",
    "     * *Indice : vous pouvez utiliser la fonction `collobert_words.index(w)` pour obtenir l'indice d'un mot dans la liste des mots*\n",
    "> * Créer une liste `words_plus_neighbors` contenant les mots et tous leurs voisins (pour la question suivante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (1.15.2)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in ./.venv/lib/python3.10/site-packages (from scipy) (2.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 5 mots les plus proches de 'mother':\n",
      "daughter\n",
      "wife\n",
      "father\n",
      "husband\n",
      "son\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mother', 'daughter', 'wife', 'father', 'husband', 'son']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tree = KDTree(embeddings)\n",
    "\n",
    "def mot_proche(mot, k=5):\n",
    "    if mot not in collobert_words:\n",
    "        print(\"mot pas dedans\")\n",
    "        return [], []  # Retourne des listes vides si le mot n'est pas trouvé\n",
    "    \n",
    "    index = collobert_words.index(mot)\n",
    "    vecteur = embeddings[index]\n",
    "\n",
    "    # trouver les k plus proches voisins\n",
    "    distances, indices = tree.query(vecteur, k=k+1)  # k+1 pour inclure le mot lui-même\n",
    "    \n",
    "    # initialiser la liste des mots et voisins\n",
    "    words_plus_neighbors = [mot]\n",
    "    \n",
    "    # ajouter les voisins à la liste\n",
    "    for i in range(1, k+1):  # commencer à 1 pour ignorer le mot lui-même\n",
    "        words_plus_neighbors.append(collobert_words[indices[i]])\n",
    "    \n",
    "    # afficher les voisins\n",
    "    print(f\"Les {k} mots les plus proches de '{mot}':\")\n",
    "    for word in words_plus_neighbors[1:]:  # on exclut le mot lui-même\n",
    "        print(word)\n",
    "    \n",
    "    return words_plus_neighbors, indices\n",
    "\n",
    "words_plus_neighbors, indices = mot_proche('mother', k=5)\n",
    "words_plus_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation avec T-SNE\n",
    "\n",
    "Les embeddings sont des vecteurs de plusieurs centaines de dimensions. Il n'est donc pas possible de les visualiser dans leur espace d'origine. Il est par contre possible d'appliquer des algorithmes de réduction de dimension pour les visualiser en 2 ou 3 dimension. Un des algorithmes de réduction de dimension permettant une visualisation en 2D est [tSNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding). \n",
    "\n",
    "#### Question\n",
    "> * créer un object `word_vectors` de type `np.array` à partir d'une liste contenant tous les embeddings des mots de la liste `words_plus_neighbors`\n",
    "> * créer un objet tSNE à partir de la librairie `from sklearn.manifold import TSNE` avec les paramètres `random_state=0`, `n_iter=2000` et `perplexity=15.0` pour une visualisation en 2 dimensions\n",
    "> * Calculer *T* la transformation tSNE des vecteur `word_vectors` en appliquant la function `.fit_transform(word_vectors)` à l'objet tSNE. Cette fonction estime les paramètres de la transformation tSNE et retourne la représentation en dimension réduite des vecteurs utilisés pour l'estimation.\n",
    "> * Utiliser la fonction `scatterplot` de [seaborn](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) pour représenter les points en 2 dimensions  et ajouter les labels des mots avec la function `plt.annotate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.10/site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.10/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 5 mots les plus proches de 'mother':\n",
      "daughter\n",
      "wife\n",
      "father\n",
      "husband\n",
      "son\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# graphics\n",
    "import matplotlib.pyplot as plt\n",
    "# display matplotlib graphics in notebook\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "# récupérer les voisins et leurs embeddings\n",
    "words_plus_neighbors, indices = mot_proche(\"mother\")\n",
    "word_vectors = embeddings[indices]\n",
    "\n",
    "# créer l'objet tSNE\n",
    "tsne = TSNE(random_state=0, n_iter=2000, perplexity=2.0)\n",
    "\n",
    "# appliquer la transformation tSNE\n",
    "T = tsne.fit_transform(word_vectors)\n",
    "\n",
    "# initialiser le graphique\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('#f9f9f9')\n",
    "\n",
    "# configurer les paramètres d'affichage\n",
    "sns.set(rc={'figure.figsize': (14, 8)})\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "# tracer les points dans le graphique\n",
    "sns.scatterplot(x=T[:, 0], y=T[:, 1])\n",
    "\n",
    "# annoter chaque point avec son mot\n",
    "for label, x, y in zip(words_plus_neighbors, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy=(x + 1, y + 1), xytext=(0, 0), textcoords='offset points')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation des embeddings \n",
    "\n",
    "### Évaluation intrinsèque\n",
    "\n",
    "[A Survey of Word Embeddings Evaluation Methods](https://arxiv.org/pdf/1801.09536.pdf), Bakarov, 2018.\n",
    "\n",
    "\n",
    ">les distances entre les mots dans un espace vectoriel pourraient être évaluées à l'aide des jugements heuristiques humains sur les distances sémantiques réelles entre ces mots (par exemple, la distance entre tasse et gobelet définies dans un intervalle continu 0, 1 serait 0.8 puisque ces mots sont synonymes, mais pas vraiment la même chose).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des datasets pré-établis et annotés manuellement\n",
    "\n",
    "Nous allons utiliser 4 jeux de données  pour évaluer la qualité des embeddings : [MEN](http://clic.cimec.unitn.it/~elia.bruni/MEN.html), [WS353R](http://www.aclweb.org/anthology/N09-1003.pdf), [SimLex999](http://leviants.com/ira.leviant/MultilingualVSMdata.html) et [MTurk](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.205.8607&rep=rep1&type=pdf). \n",
    "\n",
    "\n",
    "Ces jeux de données contiennent des paires de mots dont la proximité sémantique a été évaluée manuellement par des humains. Pour chaque dataset, dataset.X contient une liste de paires de mots et dataset.y contient le score de proximité pour chaque paire.\n",
    "\n",
    "* MEN, 3 000 paires évaluées par relation sémantique avec une échelle discrète de 0 à 50\n",
    "* SimLex-999, 999 paires évaluées avec un fort respect pour la similarité sémantique avec une échelle de 0 à 10\n",
    "* MTurk-287, 287 paires évaluées par relation sémantique avec une échelle de 0 à 5\n",
    "* WordSim-353, 353 paires évaluées par similarité sémantique (cependant, certains chercheurs trouvent les instructions pour les évaluateurs ambiguës en ce qui concerne la similarité et l'association) sur une échelle de 0 à 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "import similarity\n",
    "\n",
    "similarity_tasks = {\n",
    "    \"MEN\": similarity.fetch_MEN(),\n",
    "    \"WS353R\": similarity.fetch_WS353(which=\"relatedness\"),\n",
    "    \"SimLex999\": similarity.fetch_SimLex999(),\n",
    "    \"MTurk\": similarity.fetch_MTurk(),\n",
    "}\n",
    "\n",
    "for name, dataset in similarity_tasks.items():\n",
    "    print('\\n', name, ':',len(dataset.X),'items')\n",
    "    for data, score in zip(dataset.X[:4], dataset.y[:4]):\n",
    "        print(' '*4, ', '.join(data), ':', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats évaluation intrinsèque\n",
    "\n",
    "Notre objectif est de comparer les similarités entre les paires de mots des datasets calculées à partir des embeddings et celles données par les annotateurs humains. Si un embedding prédit les similarités de la même manière que les humains, on estime qu'il est bon. On peut donc calculer la corrélation entre la proximité donné par l'embedding et celle donnée par les humains pour chaque paire de mots du dataset.\n",
    "\n",
    "Pour cet excercice, nous allons utiliser  le classe [Embeddings](https://polyglot.readthedocs.io/en/latest/polyglot.mapping.html#module-polyglot.mapping.embeddings) de polyglot. Pour charger un embeddind avec cette classe : \n",
    "\n",
    "`glove_embeddings =  Embedding.from_glove('data/glove.6B.50d.txt')`\n",
    "\n",
    "Pour pouvoir charger les embeddings de Collobert de la même manière, il faut mettre les mots et les vecteurs dans un seul fichier, par exemple avec la commande linux `paste`:\n",
    "\n",
    "`paste -d ' ' collobert_words.lst collobert_embeddings.txt > collobert.txt`\n",
    "\n",
    "\n",
    "\n",
    "#### Question\n",
    "\n",
    "> * pour chaque embedding Collober et Glove, et chaque dataset (MEN, WS353R, SimLex999 et MTurk), calculer la similarité entre les proximités données par l'embedding et celles données par les humains. On utilisera la fonction `similarity.evaluate_similarity(word_embeddings, dataset.X, dataset.y)` qui renvoit le [coefficient de correlation de Spearman](https://fr.wikipedia.org/wiki/Corr%C3%A9lation_de_Spearman).\n",
    "> * stocker les scores  pour chaque embedding et chaque dataset dans une liste `similarity_results = []` sous forme d'un dictonnaire : `similarity_results.append({'Embeddings': embeddings_name, 'Dataset': name, 'Score': score})`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding functions\n",
    "from polyglot.mapping import Embedding\n",
    "\n",
    "similarity_results = []\n",
    "\n",
    "# Load both embeddings with Embedding.from_glove from Polyglot\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Loop on embeddings\n",
    "for embeddings_name, embeddings in [('collobert', collobert_embeddings), ('glove', glove_embeddings)]:\n",
    "    # loop on tasks\n",
    "    for name, dataset in similarity_tasks.items():\n",
    "        # compute similarity\n",
    "        # YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des résultats de similarité\n",
    "\n",
    "Le code suivant permet de visualiser les coefficients de corrélation pour chaque dataset sur les différents jeux de test.\n",
    "\n",
    "#### Question\n",
    "> * Quel est selon ces métriques le meilleur embedding ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(similarity_results, orient='columns')\n",
    "df\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('#f9f9f9')\n",
    "\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8, 6)})\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "colors = [\"#e74c3c\", \"#75d9fc\", \"#b4e0ef\", \"#34495e\", \"#e74c3c\", \"#2ecc71\"]\n",
    "ax = sns.barplot(x=\"Dataset\", y=\"Score\", hue=\"Embeddings\", data=df, errwidth=0, palette=sns.color_palette(colors))\n",
    "\n",
    "\n",
    "ax.legend(loc=9, bbox_to_anchor=(0.5, -0.1), ncol=3, fancybox=True, shadow=False)\n",
    "ax.set(xlabel=\"\", ylabel=\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation d'analogies\n",
    "\n",
    "Notre objectif est maintenant d'explorer les relations sémantiques induites par l'arithmétique sur les embeddings. Nous allons donc explorer les analogies induites par les embeddings sous forme de raisonnement du type : \"l'homme est au roi ce que la femme est à ?\", la réponse étant \"la reine\". On peut calculer la réponse avec les représentations fournies par l'embedding par :  \n",
    "\n",
    "`v = vecteur(roi)-vecteur(homme)+vecteur(femme)`. \n",
    "\n",
    "La réponse étant alors le mot dont la représentation est la plus proche du vecteur `v`. Pour trouver le mot dont le vecteur est le plus proche de `v`, il faut définir une distance dans l'espace des embeddings. Nous utiliserons la [similarité cosinus](https://fr.wikipedia.org/wiki/Similarit%C3%A9_cosinus)\n",
    "\n",
    "#### Question\n",
    ">* Implémenter la similarity cosinus à l'aide des fonctions [np.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html#numpy.dot) et [np.linalg.norm](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm)\n",
    ">* Appliquer le calcul d'analogies sur les triplets proposés ou ceux de votre choix. Observez-vous [ce phénomène](https://arxiv.org/pdf/1607.06520.pdf) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cosine_similarity(a,b):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "def sorted_by_similarity(word_embeddings, base_vector):\n",
    "    \"\"\"Returns words sorted by cosine distance to a given vector, most similar first\"\"\"\n",
    "    words_with_distance = [(my_cosine_similarity(base_vector, word_embeddings[w]), w) \n",
    "                           for w in word_embeddings.vocabulary]\n",
    "\n",
    "    return sorted(words_with_distance, key=lambda t: t[0], reverse=True)\n",
    "\n",
    "def is_redundant(word):\n",
    "    return (\n",
    "        word_1.lower() in word.lower() or\n",
    "        word_2.lower() in word.lower() or\n",
    "        word_3.lower() in word.lower())\n",
    "\n",
    "\n",
    "pairs = [(['man', 'woman'], 'king'), \n",
    "         (['man', 'programmer'], 'woman'), \n",
    "         (['father', 'doctor'], 'mother'),\n",
    "         (['father', 'facebook'], 'mother')\n",
    "        ]\n",
    "\n",
    "words_and_responses = []\n",
    "\n",
    "# Note : you may need to update the following line with your Polyglot Embeddings\n",
    "for embeddings_name, embeddings in [('collobert', collobert_embeddings), ('glove', glove_embeddings)]:\n",
    "    for pair in pairs:\n",
    "        word_1, word_2, word_3 = pair[0][0], pair[0][1], pair[1]\n",
    "        \n",
    "        closest = sorted_by_similarity(embeddings, \n",
    "                                       embeddings[word_2] - embeddings[word_1] + \n",
    "                                       embeddings[word_3])[:10]\n",
    "\n",
    "        closest = [(dist, w) for (dist, w) in closest if not is_redundant(w)] #\n",
    "        \n",
    "        print(\"{} + {} - {} = ? {}\".format(word_2, word_3, word_1, closest[0][1]))\n",
    "        words_and_responses += [word_1, word_2, word_3,closest[0][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des analogies\n",
    "\n",
    "Les relations d'analogies peuvent se visualiser dans l'espace des embeddings après réduction de dimension, par exemple avec tSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note : you may need to update the following line with your Polyglot Embeddings\n",
    "for embeddings_name, embeddings in [('collobert', collobert_embeddings), ('glove', glove_embeddings)]:\n",
    "    \n",
    "    word_vectors = np.array([embeddings[word] for word in words_and_responses[:4]])\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=0, n_iter=1000, perplexity=3.0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    T = tsne.fit_transform(word_vectors)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('#f9f9f9')\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(6, 6)})\n",
    "    sns.set(font_scale=1.3)\n",
    "\n",
    "    sns.scatterplot(x=T[:, 0], y=T[:, 1])\n",
    "    \n",
    "    for label, x, y in zip(words_and_responses, T[:, 0], T[:, 1]):\n",
    "        plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation des embeddings de BERT\n",
    "\n",
    "BERT a été un des premiers modèles de langue Transformer, entraînés sur de gros corpus, disponible librement. De nombreux modèles sont disponibles sur HuggingFace.\n",
    "\n",
    "Comme BERT est un modèle contextuel, il est nécessaire de lui faire prédire des phrases entières pour étudier les embeddings de mots qu'il produit. Dans cette section, nous allons comparer les embeddings obtenus pour des mots polysémiques en fonction de la phrase dans laquelle ils sont utilisés.\n",
    "\n",
    "En anglais, *plant* possède deux sens : celui d'usine et celui d'un végétal. Avec un embedding non contextuel, de type Glove ou Colobert, ces deux sens du mot plus sont associés à un identique embedding. Avec BERT, nous allons voir que le même mot peut avoir plusieurs embeddings en fonction du contexte.\n",
    "\n",
    "First, load the BERT model and tokenizer from HuggingFace : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load pre-trained model \n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # to access the hidden states\n",
    "                                  )\n",
    "# set the model to \"evaluation\" mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Les modèles de langues sont entrainés avec un découpe spécifique des phrases en token. Ces tokens peuvent être des mots ou des parties de mots. Il est nécessaire d'utiliser le tokenizer correspondant à chaque model.\n",
    "\n",
    "tokenizer.vocab.keys() donne la liste de tous les tokens connus du modèle de langue. \n",
    "\n",
    "#### Question\n",
    ">* combien de token différents sont connu du tokenizer de BERT ?\n",
    ">* affichez une centaine de token aléatoirement. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# number of token in tokenizer\n",
    "# YOU CODE HERE\n",
    "# sample of 100 tokens\n",
    "# YOU CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tokenizer découpe les phrases et transforme les éléments (mots ou sous-mots) en indice. \n",
    "\n",
    "BERT peut traiter plusieurs phrases mais il faut lui indiquer le découpage en phrases (segment) avec un indice : 0 pour la première phrases, 1 pour la deuxième. \n",
    "\n",
    "Deux tokens spécifiques doivent être aussi ajoutés : \n",
    "* [CLS], un token spécifique utilisé pour la classification de phrase\n",
    "* [SEP], le token de fin de phrase.\n",
    "\n",
    "#### Question\n",
    ">* Appliquer la fonction bert_tokenize sur les 3 phases et conservez les 3 vecteurs (index, token, segment)\n",
    ">* Affichez ces informations pour chacune des phrases et vérifier que le mot *plant* a bien le même indice de token dans les deux phrases où il apparait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snt1 = \"The plant has reached its maximal level of production.\"\n",
    "snt2 = \"The cars are assembled inside the factory.\"\n",
    "snt3 = \"A plant needs sunlight and water to grow well.\"\n",
    "\n",
    "\n",
    "def bert_tokenize(snt):\n",
    "    \"\"\" Apply the BERT tokenizer to a list of words representing a sentence\n",
    "        and return 3 lists: \n",
    "        - list of token indx\n",
    "        - list of token for debugging, not used by the BERT model\n",
    "        - list of sentence index\n",
    "        \"\"\"\n",
    "    # Add the special tokens.\n",
    "    tagged_snt = \"[CLS] \" + snt + \" [SEP]\" \n",
    "    # Tokenize\n",
    "    tokenized_snt = tokenizer.tokenize(tagged_snt)\n",
    "    # convert tokens to indices\n",
    "    indexed_snt = tokenizer.convert_tokens_to_ids(tokenized_snt)\n",
    "    # mark the words in sentence.\n",
    "    segments_ids = [1] * len(tokenized_snt)\n",
    "\n",
    "    return (indexed_snt, tokenized_snt, segments_ids)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inférence\n",
    "\n",
    "Pour calculer les embeddings, il est nécessaire de faire une prédiction avec le modèle BERT sur une phrase complète. La fonction *predict_hidden* convertit les listes d'indices de token et de segment en tenseur pytorch et applique le modèle. \n",
    "\n",
    "Le modème utilisé est un modèle à 12 couches. Nous allons utiliser la dernière couche caché du modèle comme embedding pour représenter les mots. D'autres solutions serait possible, comme une concaténation ou une moyene de plusieurs couches.\n",
    "\n",
    "\n",
    "#### Question\n",
    ">* Appliquer le modèle à chacune des 3 phrases et stocker les embeddings obtenus (tenseurs)\n",
    ">* Afficher la dimension des tenseurs obtenus. Quelle est la dimension du vecteur d'embedding pour chaque mot ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_hidden(indexed_snt, segments_ids):\n",
    "    \"\"\"Apply the BERT model to the input token indices and segment indices\n",
    "        and return the last hidden layer\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_snt])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "        one_hidden_layer = hidden_states[12][0]\n",
    "        \n",
    "    return one_hidden_layer\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La couche cachée renvoyée par la fonction *predict_hidden* est un tenseur contenant pour chaque token de la phrase d'entrée un vecteur contextuel le représentant. On peut utiliser ce vecteur pour représenter le sens de ce mot en fonction de son contexte. Nous allons comparer la représentation du mot polysémique *plant* en fonction de son contexte.\n",
    "\n",
    "#### Question\n",
    ">* En utilisant la [distance cosinus](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html), calculer les distances suivantes:\n",
    ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *plant* dans la phrase 3 (plant-vegetal)\n",
    ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *factory* dans la phrase 2 \n",
    ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *production* dans la phrase 2 \n",
    ">   * distance entre *plant* dans la phrase 3 (plant-vegetal) et *production* dans la phrase 2 \n",
    "> * Comment interprêter ces distances ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
